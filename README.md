# Evaluation

WORK IN PROGRESS - WORK IN PROGRESS - WORK IN PROGRESS - WORK IN PROGRESS

This repository provides the definition of the official evaluation metric of the "Person Discovery" [MediaEval](http://www.multimediaeval.org/mediaeval2015/) task.

Official Python implementation is available and will be the one used for ranking submissions.

## Python

### Installation

```bash
git clone https://github.com/MediaevalPersonDiscoveryTask/evaluation.git
cd evaluation
pip install -r requirements.txt
```

### Usage

```bash
python evaluation.py shot reference hypothesis.label hypothesis.evidence
```

## Contribute

Feel free to share your own implementations in alternative languages, using [GitHub's pull request](https://help.github.com/articles/using-pull-requests/) procedure.
We will gladly add them to this repository.
